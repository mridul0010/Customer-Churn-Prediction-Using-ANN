import streamlit as st
import pandas as pd
import numpy as np
import pickle
import tensorflow
from tensorflow import keras
from tensorflow.keras.models import load_model
from sklearn.compose import ColumnTransformer # Added for type hinting and clarity

# Set Streamlit page configuration
st.set_page_config(
    page_title="Customer Churn Predictor",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Resource Loading (Cached for performance) ---

@st.cache_resource
def load_artifacts():
    """Loads the trained model and the unified preprocessor."""
    try:
        # Load Keras Model
        with st.spinner("Loading model..."):
            model = load_model('model.keras')

        # Load Unified Preprocessor (ColumnTransformer)
        with open('preprocessed.pkl' , 'rb') as file:
            # This file now contains the ColumnTransformer with OHE, OrdinalEncoder, and StandardScaler
            preprocessor = pickle.load(file) 

        # The previous separate files (OHE_Geography.pkl, label_encoder_gender.pkl, scalar.pkl) are no longer needed
        return model, preprocessor
    except FileNotFoundError as e:
        # Updated instructions to reflect the new preprocessor filename
        st.error(f"Required artifact file not found: **{e.filename}**. Please ensure the new **'preprocessed.pkl'** file is available alongside 'model.keras'.")
        st.stop()
    except Exception as e:
        st.error(f"An error occurred during artifact loading: {e}")
        st.stop()


# Load all resources once
model, preprocessor = load_artifacts()


# --- Prediction Function ---

def predict_churn(data):
    """
    Takes a dictionary of input data, prepares it, and runs it through the unified preprocessor 
    before making a prediction.
    """
    # 1. Create DataFrame from input
    input_df = pd.DataFrame([data])
    
    # The ColumnTransformer in preprocessed.pkl expects columns in the order 
    # ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 
    #  'HasCrCard', 'IsActiveMember', 'EstimatedSalary']. 
    # We must ensure the input DataFrame is correctly ordered/selected.
    
    expected_feature_order = [
        'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 
        'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 
        'EstimatedSalary'
    ]
    
    # Select and reorder columns to match the preprocessor's feature_names_in_
    ordered_input_df = input_df[expected_feature_order]

    # 2. Apply unified preprocessor transform
    # This single step performs: Ordinal Encoding (Gender), OHE (Geography), and Scaling (all numerical)
    input_scaled = preprocessor.transform(ordered_input_df)
    
    # 3. Prediction
    prediction = model.predict(input_scaled, verbose=0)
    
    # 4. Extract probability and convert to standard Python float
    pred_prob = float(prediction[0][0])
    
    return pred_prob


# --- Streamlit UI Design ---

st.markdown("## üìä **Bank Customer Churn Risk Assessment Tool**") 
st.markdown("Use the **sidebar** to define the customer profile and calculate their churn risk.")

# Sidebar for Input Features
with st.sidebar:
    st.header("üéØ Customer Risk Assessment")
    st.markdown("---")
    
    # --- Group 1: Demographics ---
    st.subheader("1. Demographic Details")
    
    col_a, col_b = st.columns(2)
    with col_a:
        Geography = st.selectbox("üåç Geography", ('France', 'Germany', 'Spain'))
    with col_b:
        Gender = st.radio("üßç Gender", ('Male', 'Female'))

    Age = st.slider("üéÇ Age", min_value=18, max_value=92, value=40)
    st.markdown("---")

    # --- Group 2: Account Details ---
    st.subheader("2. Account Status")
    CreditScore = st.slider("‚öñÔ∏è Credit Score", min_value=300, max_value=850, value=650)
    Tenure = st.slider("‚è≥ Tenure (Years)", min_value=0, max_value=10, value=5)
    NumOfProducts = st.slider("üõí Number of Products", min_value=1, max_value=4, value=1)
    
    col_c, col_d = st.columns(2)
    with col_c:
        # Simplified display of 0/1 for binary features
        HasCrCard = st.radio("üí≥ Has Credit Card?", (1, 0), index=0, format_func=lambda x: 'Yes' if x == 1 else 'No')
    with col_d:
        IsActiveMember = st.radio("‚úÖ Is Active Member?", (1, 0), index=0, format_func=lambda x: 'Yes' if x == 1 else 'No')
        
    st.markdown("---")
    
    # --- Group 3: Financials ---
    st.subheader("3. Financials")
    Balance = st.number_input("üí∞ Account Balance ($)", min_value=0.0, max_value=250000.0, value=50000.0, step=100.0)
    EstimatedSalary = st.number_input("üíµ Estimated Salary ($)", min_value=0.0, max_value=200000.0, value=75000.0, step=100.0)
    
    st.markdown("---")
    predict_button = st.button("üöÄ Predict Churn Risk", type="primary", use_container_width=True)


# --- Main Content/Output ---
col1, col2 = st.columns([1, 1])

with col1:
    if predict_button:
        # Gather input data
        input_data = {
            'CreditScore': CreditScore,
            'Age': Age,
            'Tenure': Tenure,
            'Gender': Gender,
            'Balance': Balance,
            'NumOfProducts': NumOfProducts,
            'HasCrCard': HasCrCard,
            'Geography': Geography,
            'IsActiveMember': IsActiveMember,
            'EstimatedSalary': EstimatedSalary
        }

        with st.spinner('Calculating churn probability...'):
            # Perform prediction
            churn_probability = predict_churn(input_data)
        
        # Format the probability as a percentage
        risk_percentage = churn_probability * 100

        st.subheader("Prediction Result")
        
        # --- DESIGN CHANGE 1: Refactored Prediction Display ---
        if risk_percentage >= 50:
            risk_text = "HIGH CHURN RISK"
            icon = "üö®"
        elif risk_percentage >= 20:
            risk_text = "MODERATE CHURN RISK"
            icon = "‚ö†Ô∏è"
        else:
            risk_text = "LOW CHURN RISK"
            icon = "‚úÖ"

        with st.container(border=True):
            # Use st.metric for a clean, professional look
            st.metric(label=f"{icon} Overall Churn Probability", 
                      value=f"{risk_percentage:.2f} %", 
                      delta=risk_text)
            
            # Show confidence visually
            st.markdown(f"**Confidence Score (0.0 - 1.0):**")
            st.progress(churn_probability)
        
        st.markdown("---")
        
        # --- DESIGN CHANGE 2: Added Mock Key Factors Section ---
        st.subheader("üîé Key Contributing Factors (Mock)")
        st.info(f"""
        This prediction is primarily driven by (based on mock feature importance):
        1. **Age:** Customers over 50 often show higher churn risk.
        2. **Balance:** Customers with non-zero balance and low product count.
        3. **IsActiveMember:** Inactive status significantly increases risk.
        """)
        
    else:
        st.info("üëà Enter customer details in the sidebar and click the button to start prediction.")

with col2:
    if predict_button:
        st.subheader("Analysis & Recommendations")
        
        # --- DESIGN CHANGE 3: Enhanced Recommendation Styling ---
        if risk_percentage >= 50:
            st.error("""
            **üö® URGENT ACTION: HIGH RISK**
            This customer poses a high flight risk. Immediate retention strategies are mandatory:
            * **Personalized Offer:** Send a highly tailored offer (e.g., better interest rate or free consultation).
            * **Direct Contact:** Have a senior account manager call to address potential issues directly.
            * **Product Review:** Proactively review if their current products meet their evolving needs.
            """)
        elif risk_percentage >= 20:
            st.warning("""
            **‚ö†Ô∏è PROACTIVE MONITORING: MODERATE RISK**
            This customer requires proactive engagement and monitoring to prevent escalation to high risk:
            * **Loyalty Programs:** Introduce them to new loyalty tiers or perks before they consider leaving.
            * **Satisfaction Check:** Send a quick, high-impact survey about their satisfaction with services.
            * **Usage Incentives:** Offer small bonuses to encourage deeper product engagement.
            """)
        else:
            st.success("""
            **‚úÖ MAINTAIN & GROW: LOW RISK**
            This customer is generally stable. Focus on maximizing their value:
            * **Relationship Building:** Continue standard communication (e.g., quality newsletters, annual reviews).
            * **Upselling/Cross-selling:** Look for opportunities to introduce new, relevant products to increase stickiness.
            """)
        
        with st.expander("Show Raw Data and Features"):
            st.dataframe(pd.DataFrame([input_data]), use_container_width=True)
            st.text(f"Raw Model Output (Probability of Churn): {churn_probability:.6f}")
            
    st.markdown("---")
    st.subheader("Model Performance Summary")
    
    st.markdown("""
    This section summarizes the performance of the underlying **Artificial Neural Network (ANN)** model 
    used for prediction.
    """)
    
    # Hardcoded/Mock metrics representing the final validation performance of the ANN model
    col_metrics_a, col_metrics_b, col_metrics_c = st.columns(3)
    
    col_metrics_a.metric("Validation Accuracy", "86.12%", "+0.5%")
    col_metrics_b.metric("Validation Loss", "0.334", "-0.01")
    col_metrics_c.metric("Architecture", "3-Layer ANN", "12 Inputs")

    st.markdown("---")
    
    with st.expander("Training History (From Log Files)"):
        st.markdown("""
        The uploaded **TensorBoard log files** contain the full training history. Below is a mock chart 
        that illustrates where the actual **Accuracy and Loss curves** over the epochs would be displayed 
        after reading those files.
        """)
        # Create a placeholder line chart (Mock Data)
        chart_data = pd.DataFrame(
            np.random.randn(20, 2) / [20, 20] + [0.85, 0.35],
            columns=['Validation Accuracy (Mock)', 'Validation Loss (Mock)']
        ).cumsum() # Use cumsum to simulate an increasing/decreasing curve
        st.line_chart(chart_data)
        st.caption("Mock chart illustrating how the training curves look over 20 epochs.")
